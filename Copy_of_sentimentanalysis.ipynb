{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9650ead2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import string\n",
        "import numpy as np\n",
        "from tensorflow.keras import optimizers"
      ],
      "id": "9650ead2"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "KfKNrwWKba8S",
        "outputId": "887b5b5b-7cc7-48bc-dcd5-a04e2694bfc4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4996ee3d8d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 124\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "KfKNrwWKba8S"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/IndoNLP/indonlu.git\""
      ],
      "metadata": {
        "id": "PCz04I9bpZrR"
      },
      "id": "PCz04I9bpZrR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75e8c324"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/finance dataset - Sheet1.csv\")"
      ],
      "id": "75e8c324"
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/financial_news_mt.csv\")"
      ],
      "metadata": {
        "id": "izxW7yE7pVgd"
      },
      "id": "izxW7yE7pVgd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext_2 = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/financial_news_mt_2.csv\")"
      ],
      "metadata": {
        "id": "Rw5fbagx8qWe"
      },
      "id": "Rw5fbagx8qWe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext_3 = pd.read_csv(\"/content/indonlu/dataset/smsa_doc-sentiment-prosa/train_preprocess.tsv\", sep = \"\\t\", header = None)"
      ],
      "metadata": {
        "id": "Ue8_jRyy5yMK"
      },
      "id": "Ue8_jRyy5yMK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['label', 'content']]"
      ],
      "metadata": {
        "id": "big6QELgvNIb"
      },
      "id": "big6QELgvNIb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "qOH98CcUycMN"
      },
      "id": "qOH98CcUycMN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext = df_ext.drop(columns = [\"Unnamed: 0\", \"en_text\"])"
      ],
      "metadata": {
        "id": "0GtyoiFl2twY"
      },
      "id": "0GtyoiFl2twY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext.head()"
      ],
      "metadata": {
        "id": "bgyHqYpJ8wbs"
      },
      "id": "bgyHqYpJ8wbs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext.columns = [\"label\", \"content\"]"
      ],
      "metadata": {
        "id": "8b3DIK3lqKVZ"
      },
      "id": "8b3DIK3lqKVZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext = df_ext[df_ext[\"label\"] != \"neutral\"]"
      ],
      "metadata": {
        "id": "rj0yDpj7qOOf"
      },
      "id": "rj0yDpj7qOOf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext[\"content\"][4]"
      ],
      "metadata": {
        "id": "F-fSksNU29nL"
      },
      "id": "F-fSksNU29nL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {'positive':'up', 'negative':'down'}\n",
        "df_ext[\"label\"] = df_ext[\"label\"].map(label_dict)"
      ],
      "metadata": {
        "id": "DFD7cf8upjch"
      },
      "id": "DFD7cf8upjch",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "BE8jUDrEo3fj"
      },
      "id": "BE8jUDrEo3fj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext_2"
      ],
      "metadata": {
        "id": "kVKHtjSQ85se"
      },
      "id": "kVKHtjSQ85se",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext_3.columns = [\"content\", \"label\"]"
      ],
      "metadata": {
        "id": "G9OTc8C_564o"
      },
      "id": "G9OTc8C_564o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext_3 = df_ext_3[df_ext_3[\"label\"] != \"neutral\"]"
      ],
      "metadata": {
        "id": "_2bbEIdM6Ccm"
      },
      "id": "_2bbEIdM6Ccm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext_3"
      ],
      "metadata": {
        "id": "I5m4o_xK61oC"
      },
      "id": "I5m4o_xK61oC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a8ec31c"
      },
      "outputs": [],
      "source": [
        "df = df.iloc[0:83, :]"
      ],
      "id": "5a8ec31c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e28ab937"
      },
      "outputs": [],
      "source": [
        "label_dict = {'up':'up', 'down':'down'}\n",
        "df['label'] = df['label'].map(label_dict)"
      ],
      "id": "e28ab937"
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext_3"
      ],
      "metadata": {
        "id": "LJOpn1e66fMt"
      },
      "id": "LJOpn1e66fMt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " label_dict = {'positive':'up', 'negative':'down'}\n",
        "\n",
        " df_ext_3['label'].map(label_dict)"
      ],
      "metadata": {
        "id": "NOXQv8hK67r-"
      },
      "id": "NOXQv8hK67r-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext_3['label']"
      ],
      "metadata": {
        "id": "v0SWNe2p6-mM"
      },
      "id": "v0SWNe2p6-mM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {'positive':'up', 'negative':'down'}\n",
        "\n",
        "df_ext_3['label'] = df_ext_3['label'].map(label_dict)"
      ],
      "metadata": {
        "id": "hc5-zwt_6LO7"
      },
      "id": "hc5-zwt_6LO7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ext_3"
      ],
      "metadata": {
        "id": "aJZTVc9c6k4L"
      },
      "id": "aJZTVc9c6k4L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "I0gdtRSIjVpu"
      },
      "id": "I0gdtRSIjVpu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.append(df_ext)"
      ],
      "metadata": {
        "id": "_tlcQPl6jqjt"
      },
      "id": "_tlcQPl6jqjt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.append(df_ext_2)"
      ],
      "metadata": {
        "id": "X3_am2Ct8-5M"
      },
      "id": "X3_am2Ct8-5M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.append(df_ext_3)"
      ],
      "metadata": {
        "id": "oVJueE1q6SHz"
      },
      "id": "oVJueE1q6SHz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(20)"
      ],
      "metadata": {
        "id": "nnenE9ODrjtk"
      },
      "id": "nnenE9ODrjtk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_length'] = df[\"content\"].str.split().str.len()"
      ],
      "metadata": {
        "id": "JbfB6jctEYud"
      },
      "id": "JbfB6jctEYud",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text_length\"][:83].hist(bins=10)"
      ],
      "metadata": {
        "id": "8GwhRSeaElqa"
      },
      "id": "8GwhRSeaElqa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = df[df[\"text_length\"] <= 30]"
      ],
      "metadata": {
        "id": "E2QycaPfE9O_"
      },
      "id": "E2QycaPfE9O_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "SZfcW8pc7JWm"
      },
      "id": "SZfcW8pc7JWm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=df[:83]\n",
        "train=df[83:]"
      ],
      "metadata": {
        "id": "HMtfWTjw727y"
      },
      "id": "HMtfWTjw727y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.iloc[2]"
      ],
      "metadata": {
        "id": "7eJ9cbT3F16C"
      },
      "id": "7eJ9cbT3F16C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[\"content\"][2]"
      ],
      "metadata": {
        "id": "HZReZzO_GNIs"
      },
      "id": "HZReZzO_GNIs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos = train[train[\"label\"] == \"up\"]\n",
        "train_pos = train_pos.sample(4000 , replace = True)"
      ],
      "metadata": {
        "id": "80wGI0K-7YiU"
      },
      "id": "80wGI0K-7YiU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_neg = train[train[\"label\"] == \"down\"]"
      ],
      "metadata": {
        "id": "KKv5ziHO7er7"
      },
      "id": "KKv5ziHO7er7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_all = train_pos.append(train_neg)"
      ],
      "metadata": {
        "id": "hHVgLfyX7iT_"
      },
      "id": "hHVgLfyX7iT_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_all[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "c9-z0h1C7psQ"
      },
      "id": "c9-z0h1C7psQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tag import pos_tag\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "hH-bsn3BzDEr"
      },
      "id": "hH-bsn3BzDEr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55903828"
      },
      "outputs": [],
      "source": [
        "def remove_emojis(data):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\" \n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  \n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', data)\n",
        "\n",
        "def cleansing(text):\n",
        "    text = remove_emojis(text)\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = text.lower()\n",
        "    word_list = word_tokenize(text)\n",
        "    word_list = [word for word in word_list if len(word) > 2 and word.isalnum()]\n",
        "    word_list = [word for word in word_list if string.punctuation not in word]\n",
        "    text = ' '.join(word_list)\n",
        "    return text"
      ],
      "id": "55903828"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxU3SXrncL7U"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ],
      "id": "oxU3SXrncL7U"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7a708cd"
      },
      "outputs": [],
      "source": [
        "train['content'] = train['content'].apply(cleansing)\n",
        "test['content'] = test['content'].apply(cleansing)"
      ],
      "id": "a7a708cd"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "kWlaEgiafus9"
      },
      "id": "kWlaEgiafus9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, EncoderDecoderModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"cahya/bert2gpt-indonesian-summarization\")\n",
        "tokenizer.bos_token = tokenizer.cls_token\n",
        "tokenizer.eos_token = tokenizer.sep_token\n",
        "model = EncoderDecoderModel.from_pretrained(\"cahya/bert2gpt-indonesian-summarization\")"
      ],
      "metadata": {
        "id": "D-mDXKUkfw3u"
      },
      "id": "D-mDXKUkfw3u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def machine_summarization(article):\n",
        "  input_ids = tokenizer.encode(article, return_tensors='pt', \n",
        "                               padding=True, truncation=True, \n",
        "                               max_length=512, add_special_tokens = True)\n",
        "  summary_ids = model.generate(input_ids,\n",
        "              min_length=5,\n",
        "              max_length=20, \n",
        "              early_stopping=True,\n",
        "              no_repeat_ngram_size=2,\n",
        "              use_cache=True,\n",
        "              do_sample = True,\n",
        "              top_k = 50,\n",
        "              top_p = 0.95)\n",
        "\n",
        "  summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "  print(summary_text)\n",
        "  return summary_text\n"
      ],
      "metadata": {
        "id": "Cbt_gIgqf4VC"
      },
      "id": "Cbt_gIgqf4VC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "summary = machine_summarization('sudah hampir dua tahun kita menghadapi pandemi ternyata dampaknya pun berhasil membuat raksasa terseok awal februari 2022 ini saja kita sudah mendapat berita tentang maskapai penerbangan raksasa indonesia yang dikabarkan kolaps dan akan melakukan phk massal bagaimana fakta dan kronologinya garuda indonesia bangkrut isu garuda indonesia tbk giaa akan bangkrut mencuat saat diketahui bahwa perusahaan tersebut akan menemui kementerian ketenagakerjaan kemnaker ')"
      ],
      "metadata": {
        "id": "0Qrz-r6DkPzT"
      },
      "id": "0Qrz-r6DkPzT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "id": "YEkqNEwSktQ2"
      },
      "id": "YEkqNEwSktQ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "summarized_content = [machine_summarization(text) for text in df['content'].values[:83]]"
      ],
      "metadata": {
        "id": "h0DWKyjegEjT"
      },
      "id": "h0DWKyjegEjT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[\"content\"] = summarized_content\n",
        "test[\"content\"] = test[\"content\"].apply(cleansing)"
      ],
      "metadata": {
        "id": "9W2E50i93eWl"
      },
      "id": "9W2E50i93eWl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"dataframe_all.csv\")"
      ],
      "metadata": {
        "id": "b_0AqRF9Jo8o"
      },
      "id": "b_0AqRF9Jo8o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "BNOg1zAjpIjG"
      },
      "id": "BNOg1zAjpIjG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Aep8ZXxk8bK0"
      },
      "id": "Aep8ZXxk8bK0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "117efc50"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")"
      ],
      "id": "117efc50"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb15f400"
      },
      "outputs": [],
      "source": [
        "vocab_size = 30000\n",
        "embedding_dim = 256\n",
        "max_length = 50\n",
        "trunc_type = 'post'\n",
        "oov_tok = '<OOV>'\n",
        "padding_type = 'post'"
      ],
      "id": "fb15f400"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89514eea"
      },
      "outputs": [],
      "source": [
        "label2idx = {'down': 1 ,   'up': 0}\n",
        "idx2label = {y:x for x,y in label2idx.items()}"
      ],
      "id": "89514eea"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14d42e73"
      },
      "outputs": [],
      "source": [
        "idx2label"
      ],
      "id": "14d42e73"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "389457f3"
      },
      "outputs": [],
      "source": [
        "train['label_tf'] = train['label'].map(label2idx)\n",
        "test['label_tf'] = test['label'].map(label2idx)"
      ],
      "id": "389457f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39d58982"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok) # di inference cukup load tokenizer\n",
        "\n",
        "tokenizer.fit_on_texts(df['content'].tolist())\n",
        "word_index = tokenizer.word_index"
      ],
      "id": "39d58982"
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# loading\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "metadata": {
        "id": "u8M8epAuP407"
      },
      "id": "u8M8epAuP407",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da85b2df"
      },
      "outputs": [],
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(train['content'].tolist())\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding = padding_type, truncating = trunc_type)\n",
        "testing_sentences = tokenizer.texts_to_sequences(test['content'].tolist())\n",
        "testing_padded = pad_sequences(testing_sentences, maxlen=max_length, padding = padding_type, truncating = trunc_type)"
      ],
      "id": "da85b2df"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "034c1d2c"
      },
      "outputs": [],
      "source": [
        "training_labels_final = np.array(train['label_tf'].tolist())\n",
        "testing_labels_final = np.array(test['label_tf'].tolist())"
      ],
      "id": "034c1d2c"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "HvQV5pjAQ8EN"
      },
      "id": "HvQV5pjAQ8EN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20e36b1b"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim , input_length = max_length),\n",
        "    #tf.keras.layers.Dropout(0.9) ,\n",
        "   # tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
        "    # tf.keras.layers.MaxPooling1D(pool_size = 4 ) , \n",
        "   #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8)) ,\n",
        "    #tf.keras.layers.LSTM(16) , \n",
        "    tf.keras.layers.Dropout(0.5) , \n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(4)),\n",
        "     #tf.keras.layers.Dense(64 , activation='relu') , \n",
        "    tf.keras.layers.Dense(16 , activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5) ,\n",
        "   tf.keras.layers.Dense(256 , activation='relu'),\n",
        "    tf.keras.layers.Dense( 1 , activation='sigmoid')\n",
        "])\n",
        "\n",
        "callbacks = ModelCheckpoint(\"best_model.h5\",\n",
        "    monitor='val_accuracy',\n",
        "    verbose=1,\n",
        "    save_best_only=True)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer= optimizers.Adam(learning_rate = 0.001) , \n",
        "              metrics=['accuracy']) \n",
        "model.summary()\n",
        "# cross entropy = negative log likelihood"
      ],
      "id": "20e36b1b"
    },
    {
      "cell_type": "code",
      "source": [
        "testing_padded"
      ],
      "metadata": {
        "id": "Z4iQnVFNB4nY"
      },
      "id": "Z4iQnVFNB4nY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_labels_final"
      ],
      "metadata": {
        "id": "_HO4ixViDbmM"
      },
      "id": "_HO4ixViDbmM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45951bfb"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "history = model.fit(train_padded, training_labels_final, batch_size = 128 ,  \n",
        "                    epochs=num_epochs, validation_data=(testing_padded, testing_labels_final),\n",
        "              callbacks=[callbacks])"
      ],
      "id": "45951bfb"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])"
      ],
      "metadata": {
        "id": "K_FT-Epxspru"
      },
      "id": "K_FT-Epxspru",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(testing_padded, testing_labels_final, batch_size = 1)"
      ],
      "metadata": {
        "id": "_qawCXNItf7U"
      },
      "id": "_qawCXNItf7U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8opWwRPvT2H"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(history.history.keys())\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "id": "i8opWwRPvT2H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba12a390"
      },
      "outputs": [],
      "source": [
        "\"\"\"model.save('model.h5')\"\"\""
      ],
      "id": "ba12a390"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"if __name__ == '__main__':\n",
        "    model.save(\"model.h5\")\"\"\""
      ],
      "metadata": {
        "id": "q_5NEEdnjfIt"
      },
      "id": "q_5NEEdnjfIt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"if __name__ == '__main__':\n",
        "    model.save(\"model.pkl\")\"\"\""
      ],
      "metadata": {
        "id": "47vb-f-3kDLZ"
      },
      "id": "47vb-f-3kDLZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c05de99"
      },
      "outputs": [],
      "source": [
        "\"\"\"import io, json\n",
        "tokenizer_json = tokenizer.to_json()\n",
        "with io.open('saved_model/tokenizer.json', 'w', encoding='utf-8') as f:\n",
        "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\"\"\""
      ],
      "id": "1c05de99"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bf5f2b3"
      },
      "outputs": [],
      "source": [
        "\"\"\"with open('saved_model/label2idx.json', 'w') as fp:\n",
        "    json.dump(label2idx, fp)\n",
        "with open('saved_model/idx2label.json', 'w') as fp:\n",
        "    json.dump(idx2label, fp)\"\"\""
      ],
      "id": "6bf5f2b3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac2bd318"
      },
      "outputs": [],
      "source": [
        "#def tf_prediction(input_text, model, tokenizer):\n",
        "   # input_sequence = tokenizer.texts_to_sequences([input_text])\n",
        "   # input_padded = pad_sequences(input_sequence, maxlen=50, padding = 'post', truncating = 'post')\n",
        "   # predicted = model(input_padded)\n",
        "   # print(predicted)\n",
        "   # label_predicted = np.argmax(predicted[0])\n",
        "   # return label_predicted, predicted[0][label_predicted]\n",
        "\n",
        "#def tf_prediction_batch(list_text, model, tokenizer):\n",
        "  #  input_sequence = tokenizer.texts_to_sequences(list_text)\n",
        "   # input_sequence = pad_sequences(input_sequence, maxlen=50, padding = 'post', truncating = 'post')\n",
        "   # print(input_sequence.shape)\n",
        "   # predicted = model(input_sequence)\n",
        "   # label_predicted = np.argmax(predicted, axis = 1)\n",
        "   # return predicted, label_predicted"
      ],
      "id": "ac2bd318"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b6480f2"
      },
      "outputs": [],
      "source": [
        "#output_label = tf_prediction('krisis moneter indonesia', model, tokenizer )"
      ],
      "id": "1b6480f2"
    },
    {
      "cell_type": "code",
      "source": [
        "#output_label"
      ],
      "metadata": {
        "id": "0AU4u9YOU27u"
      },
      "id": "0AU4u9YOU27u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"idx2label = {y:x for x,y in label2idx.items()}\"\"\""
      ],
      "metadata": {
        "id": "ZhAm9fslT4hL"
      },
      "id": "ZhAm9fslT4hL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"idx2label[output_label[0]]\"\"\""
      ],
      "metadata": {
        "id": "9GYFtVZnUm3p"
      },
      "id": "9GYFtVZnUm3p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/best_model.h5\" \"/content/gdrive/MyDrive/Flask NLP\""
      ],
      "metadata": {
        "id": "GCPsUKzVUn0O"
      },
      "id": "GCPsUKzVUn0O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "27xtlvUDwHsO"
      },
      "id": "27xtlvUDwHsO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/tokenizer.pickle\" \"/content/gdrive/MyDrive/Flask NLP\""
      ],
      "metadata": {
        "id": "rMb5LLt8wH_A"
      },
      "id": "rMb5LLt8wH_A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9VxBw-xVwmBY"
      },
      "id": "9VxBw-xVwmBY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy_of_sentimentanalysis.ipynb",
      "provenance": []
    },
    "environment": {
      "name": "pytorch-gpu.1-9.m74",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m74"
    },
    "kernelspec": {
      "display_name": "Python [conda env:general]",
      "language": "python",
      "name": "conda-env-general-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}